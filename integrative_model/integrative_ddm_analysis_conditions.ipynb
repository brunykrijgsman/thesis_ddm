{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Integrative DDM Analysis with Conditions\n",
        "\n",
        "This notebook performs analysis of the integrative drift-diffusion model (DDM) including recovery plots, posterior predictive checks, and simulation-based calibration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:bayesflow:Using backend 'jax'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/brunykrijgsman/thesis-ddm/integrative_model\n"
          ]
        }
      ],
      "source": [
        "# =====================================================================================\n",
        "# Initialize JAX backend\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# Import modules\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sys\n",
        "from bayesflow.approximators import ContinuousApproximator\n",
        "\n",
        "# Set up paths for notebook environment\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.insert(0, parent_dir)\n",
        "\n",
        "import integrative_ddm_sim as ddm\n",
        "import keras\n",
        "import bayesflow as bf\n",
        "from bayesflow.networks import SetTransformer, CouplingFlow\n",
        "from bayesflow.adapters import Adapter\n",
        "from bayesflow.simulators import make_simulator\n",
        "\n",
        "from plots import calibration_histogram\n",
        "from shared.plots import recovery, plot_gamma_recovery_with_mode, compute_recovery_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load checkpoint - relative to current file\n",
        "CHECKPOINT_PATH = os.path.join(current_dir, 'checkpoints', 'jax_simple_integrative_ddm_checkpoint_seed12_uniform_new_sigma_beta.keras')\n",
        "\n",
        "# Create save directory - relative to current file\n",
        "save_dir = os.path.join(current_dir, 'Figures')\n",
        "os.makedirs(save_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Making simulator...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/brunykrijgsman/miniforge3/envs/tf/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 303 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# Define meta function\n",
        "def meta():\n",
        "    return dict(n_obs=100)\n",
        "\n",
        "# Make simulator\n",
        "print(\"Making simulator...\")\n",
        "simulator = make_simulator([ddm.prior, ddm.likelihood], meta_fn=meta)\n",
        "\n",
        "adapter = (\n",
        "    Adapter()\n",
        "    .broadcast(\"n_obs\", to=\"choicert\")    \n",
        "    .as_set([\"choicert\", \"z\"])\n",
        "    .standardize(exclude=[\"n_obs\"])\n",
        "    .convert_dtype(\"float64\", \"float32\")\n",
        "    .concatenate([\"alpha\", \"tau\", \"beta\", \"mu_delta\", \"eta_delta\", \"gamma\", \"sigma\"], into=\"inference_variables\")\n",
        "    .concatenate([\"choicert\", \"z\"], into=\"summary_variables\")\n",
        "    .rename(\"n_obs\", \"inference_conditions\")\n",
        ")\n",
        "# Load approximator\n",
        "approximator = keras.saving.load_model(CHECKPOINT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 100)\n",
            "1.3251421500780303\n",
            "(1, 10000)\n",
            "dict_keys(['n_obs', 'alpha', 'tau', 'beta', 'mu_delta', 'eta_delta', 'gamma', 'sigma', 'choicert', 'z'])\n",
            "(50, 1)\n",
            "(50, 100)\n"
          ]
        }
      ],
      "source": [
        "# 10k rows = 100 participants / 100 trials\n",
        "data = sio.loadmat(os.path.join(current_dir, 'data/integrative_ddm_data_SNR_high_COUP_high_DIST_gaussian.mat'))\n",
        "nparts = data['nparts'][0][0]\n",
        "ntrials = data['ntrials'][0][0]\n",
        "print(f\"{data['alpha'].shape}\")\n",
        "print(f\"{data['alpha'][0][10]}\")\n",
        "print(f\"{data['choicert'].shape}\")\n",
        "all_post_draws = []\n",
        "\n",
        "# Simulate validation data (unseen during training)\n",
        "val_sims = simulator.sample(50)\n",
        "post_draws = approximator.sample(conditions=val_sims, num_samples=50)\n",
        "print(val_sims.keys())\n",
        "\n",
        "# (50, 1)\n",
        "print(val_sims['alpha'].shape)\n",
        "\n",
        "# (50, 100)\n",
        "print(val_sims['choicert'].shape)\n",
        "\n",
        "reshaped_data = {\n",
        "    'n_obs': np.empty((nparts, 1)),\n",
        "    'alpha': np.empty((nparts, 1)),\n",
        "    'tau': np.empty((nparts, 1)), \n",
        "    'beta': np.empty((nparts, 1)),\n",
        "    'mu_delta': np.empty((nparts, 1)),\n",
        "    'eta_delta': np.empty((nparts, 1)),\n",
        "    'gamma': np.empty((nparts, 1)),\n",
        "    'sigma': np.empty((nparts, 1)),\n",
        "    'choicert': np.empty((nparts, ntrials)),\n",
        "    'z': np.empty((nparts, ntrials))\n",
        "}\n",
        "\n",
        "for npart in range(nparts):\n",
        "    data_start = npart * ntrials\n",
        "    data_end = (npart + 1) * ntrials\n",
        "\n",
        "    # print(f\"Sampling for participant {npart+1} of {nparts} ({data_start} to {data_end})\")\n",
        "\n",
        "    reshaped_data['n_obs'][npart] = ntrials\n",
        "    reshaped_data['alpha'][npart] = data['alpha'][0][npart]\n",
        "    reshaped_data['tau'][npart] = data['tau'][0][npart]\n",
        "    reshaped_data['beta'][npart] = data['beta'][0][npart]\n",
        "    reshaped_data['mu_delta'][npart] = data['mu_delta'][0][npart]\n",
        "    reshaped_data['eta_delta'][npart] = data['eta_delta'][0][npart]\n",
        "    reshaped_data['gamma'][npart] = data['gamma'][0][npart]\n",
        "    reshaped_data['sigma'][npart] = data['sigma'][0][npart]\n",
        "    reshaped_data['choicert'][npart] = data['choicert'][0][data_start:data_end]\n",
        "    reshaped_data['z'][npart] = data['z'][0][data_start:data_end]\n",
        "\n",
        "    # data_subset = {\n",
        "    #     'n_obs': ntrials,\n",
        "    #     'alpha': data['alpha'][0][npart],\n",
        "    #     'tau': data['tau'][0][npart], \n",
        "    #     'beta': data['beta'][0][npart],\n",
        "    #     'mu_delta': data['mu_delta'][0][npart],\n",
        "    #     'eta_delta': data['eta_delta'][0][npart],\n",
        "    #     'gamma': data['gamma'][0][npart],\n",
        "    #     'sigma': data['sigma'][0][npart],\n",
        "    #     'choicert': data['choicert'][0][data_start:data_end],\n",
        "    #     'z': data['z'][0][data_start:data_end]\n",
        "    # }\n",
        "\n",
        "    # ()   \n",
        "    # print(data_subset['alpha'].shape)\n",
        "    # print(data_subset['alpha'])\n",
        "\n",
        "    # (100,)\n",
        "    # print(data_subset['choicert'].shape)\n",
        "\n",
        "\n",
        "# (50, 1)\n",
        "# print(reshaped_data['alpha'].shape)\n",
        "\n",
        "# (50, 100)\n",
        "# print(reshaped_data['choicert'].shape)\n",
        "\n",
        "post_draws = approximator.sample(conditions=reshaped_data, num_samples=ntrials)\n",
        "#print(f\"post_draws keys: {post_draws.keys()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "params: ['alpha', 'tau', 'beta', 'mu_delta', 'eta_delta', 'gamma', 'sigma']\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'savefig'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# plot_gamma_recovery(estimates['gamma'], prior_samples=prior_gamma)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Recovery plot\u001b[39;00m\n\u001b[1;32m     16\u001b[0m f \u001b[38;5;241m=\u001b[39m recovery(post_draws, reshaped_data)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecovery_plot_12_uniform150_new_sigma2.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'savefig'"
          ]
        }
      ],
      "source": [
        "from shared.plots import recovery, plot_gamma_recovery_with_mode, compute_recovery_metrics\n",
        "\n",
        "# Prior samples — same way your data was generated:\n",
        "prior_signs = np.random.choice([-1, 1], size=10000)\n",
        "prior_gamma = np.random.uniform(2, 3, size=10000) * prior_signs\n",
        "\n",
        "# Gamma plot\n",
        "estimates = {\n",
        "    'gamma': post_draws['gamma']      \n",
        "}\n",
        "\n",
        "# plot_gamma_recovery(estimates['gamma'], prior_samples=prior_gamma)\n",
        "# plt.show()\n",
        "\n",
        "# Recovery plot\n",
        "f = recovery(post_draws, reshaped_data)\n",
        "f.savefig(os.path.join(save_dir, 'recovery_plot_12_uniform150_new_sigma2.png'))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'prior_samples' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check recovery metrics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m compute_recovery_metrics(post_draws, val_sims, \u001b[43mprior_samples\u001b[49m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prior_samples' is not defined"
          ]
        }
      ],
      "source": [
        "# Check recovery metrics\n",
        "compute_recovery_metrics(post_draws, val_sims, prior_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Number of dimensions is greater than number of samples. This results in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Note that `gaussian_kde` interprets each *column* of `dataset` to be a point; consider transposing the input to `dataset`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m gamma_targets \u001b[38;5;241m=\u001b[39m reshaped_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot recovery\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplot_gamma_recovery_with_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma_estimates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print sign recovery accuracy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m compute_gamma_sign_recovery(gamma_estimates, gamma_targets)\n",
            "File \u001b[0;32m~/thesis-ddm/shared/plots.py:173\u001b[0m, in \u001b[0;36mplot_gamma_recovery_with_mode\u001b[0;34m(gamma_estimates, gamma_targets)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_gamma_recovery_with_mode\u001b[39m(gamma_estimates, gamma_targets):\n\u001b[0;32m--> 173\u001b[0m     posterior_modes \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_posterior_modes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma_estimates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     lower_bounds, upper_bounds \u001b[38;5;241m=\u001b[39m compute_credible_intervals(gamma_estimates, ci\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m95\u001b[39m)\n\u001b[1;32m    176\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
            "File \u001b[0;32m~/thesis-ddm/shared/plots.py:149\u001b[0m, in \u001b[0;36mcompute_posterior_modes\u001b[0;34m(gamma_estimates)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_participants):\n\u001b[1;32m    148\u001b[0m     samples \u001b[38;5;241m=\u001b[39m gamma_estimates[i, :]\n\u001b[0;32m--> 149\u001b[0m     kde \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_kde\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     x_grid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m    151\u001b[0m     density \u001b[38;5;241m=\u001b[39m kde(x_grid)\n",
            "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.10/site-packages/scipy/stats/_kde.py:220\u001b[0m, in \u001b[0;36mgaussian_kde.__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn:\n\u001b[1;32m    214\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of dimensions is greater than number of samples. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis results in a singular data covariance matrix, which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot be treated using the algorithms implemented in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gaussian_kde`. Note that `gaussian_kde` interprets each \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*column* of `dataset` to be a point; consider transposing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe input to `dataset`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bandwidth(bw_method\u001b[38;5;241m=\u001b[39mbw_method)\n",
            "\u001b[0;31mValueError\u001b[0m: Number of dimensions is greater than number of samples. This results in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Note that `gaussian_kde` interprets each *column* of `dataset` to be a point; consider transposing the input to `dataset`."
          ]
        }
      ],
      "source": [
        "# Get gamma estimates and targets\n",
        "gamma_estimates = post_draws['gamma']\n",
        "gamma_targets = reshaped_data['gamma'].flatten()\n",
        "\n",
        "# Plot recovery\n",
        "plot_gamma_recovery_with_mode(gamma_estimates, gamma_targets)\n",
        "\n",
        "# Print sign recovery accuracy\n",
        "# compute_gamma_sign_recovery(gamma_estimates, gamma_targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Posterior predictive check\n",
        "# You need to define how to simulate new data given posterior samples\n",
        "# Check your simulator's interface\n",
        "# ppc_fig = plot_posterior_predictive_check(\n",
        "#     make_simulator([ddm.prior, ddm.likelihood], meta_fn=meta), post_draws, val_sims,\n",
        "#     stat_fn=np.mean,  # or np.std, skew, etc.\n",
        "#     observed_key=\"choicert\",\n",
        "# )\n",
        "# ppc_fig.savefig(os.path.join(save_dir, \"posterior_predictive_check.png\"))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Simulation-Based Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define variable names explicitly\n",
        "parameter_names = [\"alpha\", \"tau\", \"beta\", \"mu_delta\", \"eta_delta\", \"gamma\", \"sigma\"]\n",
        "\n",
        "# Filter val_sims to only include parameter keys\n",
        "val_sims_params = {k: v for k, v in reshaped_data.items() if k in parameter_names}\n",
        "\n",
        "print(\"Post draws shapes:\", {k: v.shape for k, v in post_draws.items()})\n",
        "print(\"Val sims params shapes:\", {k: v.shape for k, v in val_sims_params.items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calibration ECDF plot\n",
        "ecdf = bf.diagnostics.plots.calibration_ecdf(\n",
        "    estimates=post_draws, \n",
        "    targets=reshaped_data,\n",
        "    variable_names=parameter_names,\n",
        "    difference=True,\n",
        "    rank_type=\"distance\"\n",
        ")\n",
        "ecdf.savefig(os.path.join(save_dir, 'calibration_ecdf_12_uniform150_new_sigma2.1.png'))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calibration histogram\n",
        "sbc = calibration_histogram(\n",
        "    estimates=post_draws, \n",
        "    targets=val_sims_params,\n",
        "    variable_keys=parameter_names,\n",
        "    num_bins=10,\n",
        "    binomial_interval=0.99,\n",
        "    label_fontsize=16,\n",
        "    title_fontsize=18\n",
        ")\n",
        "sbc.savefig(os.path.join(save_dir, 'calibration_histogram_12_uniform150_new_sigma2.1.png'))\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
